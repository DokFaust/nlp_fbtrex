{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argentine Election Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook I analyze a Spanish dataset set up during the [Argentine legislative election](https://en.wikipedia.org/wiki/Argentine_legislative_election,_2017) of 2017. \n",
    "\n",
    "This dataset contains the data of 9 facebook bots, crawled over a period of 16 days, following 45 sources.\n",
    "\n",
    "## Dataset\n",
    "The dataset was prepared by the [__Facebook Tracking Exposed__](https://facebook.tracking.exposed/) project and can be retrieved in a convenient JSON format from the specific Github [__repo__](https://github.com/tracking-exposed/experiments-data/tree/master/silver).\n",
    "There are two separate files that we'll try to breakdown:\n",
    "* __fbtrex-data-\\*.json__ - Contains all impressions relative to single users\n",
    "* __semantic-entities.json__ - Contains all available metadata regarding posts\n",
    "\n",
    "The text field of every posts is enclosed in \"semantic-entities.json\", while I can use \"fbtrex-data-\\*.json\" to correlate which user has visualized this content, thus providing an easy way to investigate the Facebook filter bubble.\n",
    "Given a ready working environment, as explained is the README.md of this repo, just go ahead and download the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Download Argentine datasetin a data subdir\n",
    "mkdir data && cd data\n",
    "wget https://github.com/tracking-exposed/experiments-data/blob/master/silver/fbtrex-data-1.json.zip\n",
    "wget https://github.com/tracking-exposed/experiments-data/blob/master/silver/semantic-entities.json.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__Note__: This commands are supposed to be executed in a bash environment, not in the notebook itself. The operation may fail due to permissions.\n",
    "\n",
    "Extract the content from the zip archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Extract JSON from zipped archives\n",
    "cd data\n",
    "unzip fbtrex-data-1.json.zip\n",
    "unzip semantic-entities.json.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have the dataset in JSON format, we can use the [JSON Python library](https://docs.python.org/3/library/json.html) to decode its content and store it in a Python variable. The variable type depends on the actual content of the provided file, by [default](https://docs.python.org/3/library/json.html#json-to-py-table) a JSON object is decoded to a dict and an arrays to a list. The recommended approach for working with encoded text files, is to use the [codecs Python library](https://docs.python.org/3/library/codecs.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "with codecs.open('data/semantic-entities.json',encoding='utf_8') as data_json:    \n",
    "    data = json.load(data_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print to stdout the content of the parsed JSON file just use [pprint](https://docs.python.org/3/library/pprint.html), the data pretty printer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's useful to check if the casting was performed correctly before proceding, the resulting decoded type can be inspected with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the JSON is now a list. How many entities do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_len = len(data)\n",
    "print('There are {} total elements to analyze'.format(data_len+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go deeper. We decoded the JSON to a list, but what kind of list is it? What happened to JSON objects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data_len):\n",
    "    print(type(data[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a nested list of dictionaries! Let's print the dict_keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(data_len):\n",
    "    print(data[i].keys())cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting: in the provided dataset there are some entities that don't have a \"__text__\" field. So let's first take only the elements that have a text field and  put them in a new non-nested list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tex = []\n",
    "for i in range(data_len):\n",
    "    if 'text' in data[i]:\n",
    "        tex.append(data[i]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better. We now have an actual list. Again, how many entities do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tex_len = len(tex)\n",
    "print('There are actually {} text elements to analyze'.format(tex_len+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
